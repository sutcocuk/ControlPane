[Bundle Replication Failure]
display.general.type = statistics
display.page.search.tab = statistics
search = index=_internal  source=*/metrics.log* group=bundle_replication name=bundle_metadata bundle_type=full_bundle\
| lookup assets.csv host\
| mvexpand search_group\
| search search_group = *searchheadclustergroup*\
| stats dc(host) as dhost by host search_group\
\
| append \
    [ search index=_internal  source=*/metrics.log* group=bundle_replication name=bundle_metadata bundle_type=full_bundle earliest=-130m latest=-60m\
     | lookup assets.csv host\
     | mvexpand search_group\
     | search search_group = *searchheadclustergroup*\
     | stats dc(host) as dhost by host search_group]\
| stats c(dhost) as chost by host\
| where chost < 2\
\
``` Toevoegen Klantnaam ```\
| eval klantnaam = `klantnaam`

[Cold_Storage_vol]
search = index=_internal sourcetype=splunkd TERM(exceeds) TERM(volumemanager) TERM(trim) "Size exceeds max, will have to trim " NOT Primary\
| fields + host, _raw\
``` Toevoegen Klantnaam ```\
| eval klantnaam = `klantnaam`

[Cribl failed task execution]
search = index=cribl_logs ( api TaskExecutor error "failed to execute task" ) OR ( scheduledJob skipped consecutiveSkips!=1) NOT adhoc \
| eval job = coalesce(jobId,scheduledJob) , reason = if(isnull(reason),max(totalSkips)." skipped runs",reason)| stats latest(_time) as _time latest(reason) as reason  by job message\
``` Toevoegen Klantnaam ```\
| eval klantnaam = `klantnaam`

[Datamodel Partitie volume treshold exceeded]
search = | rest "services/data/index-volumes"\
| lookup assets.csv host as splunk_server\
| search search_group = *indexer*\
| eval dmc_volume=if(isnotnull(title),title,'data.name')\
| where NOT ('dmc_volume' == "_splunk_summaries")\
| fields - _dmc_volume \
| eval volumeSizeGB=if((total_size > 1),round((total_size / 1024),2),null()), sizeUsagePerc=((total_size / max_size) * 100)\
| search name=datamodel\
| where sizeUsagePerc > 90\
\
``` Toevoegen Klantnaam ```\
| eval klantnaam = `klantnaam`

[Indexer_Issue]
search = index=_internal sourcetype=splunkd eventType=connect_fail \
[| inputlookup assets.csv\
| search search_group="dmc_group_cluster_master"\
| table host]\
| stats count by destHost\
\
``` Toevoegen Klantnaam ```\
| eval klantnaam = `klantnaam`

[Indexer_Queue_vol]
search = | rest /services/server/introspection/indexer\
 | fields splunk_server, status, reason\
     | eval severity_level = if(status == "normal", 0, 2)\
     | rename splunk_server as instance\
     \
``` Toevoegen Klantnaam ```\
| eval klantnaam = `klantnaam`

[Internal_Errors]
search = index=_internal  sourcetype=splunkd   NOT DispatchManager \
    "The minimum free disk space" OR "No space left on device" OR "KV Store process terminated" OR  ("Linux transparent hugepage support, enabled="  enabled!="never") OR ("ulimit - Limit: open files") \
[| inputlookup assets.csv | dedup host | table host\
| append [| makeresults |eval host = `HF_SUF_hosts`| makemv delim="," host| mvexpand host|table host]]\
| table _raw host\
\
``` Toevoegen Klantnaam ```\
| eval klantnaam = `klantnaam`

[Lookup assets.csv geshared]
action.email.inline = 1
action.email.sendresults = 1
alert.digest_mode = 0
alert.suppress = 0
alert.track = 0
search = |rest splunk_server=local /services/data/lookup-table-files/assets.csv\
| stats c\
| eval status = if(c = 0, "Not Good", "Good")\
| search status = "Not Good"\
\
``` Toevoegen Klantnaam ```\
| eval klantnaam = `klantnaam`

[Macro waardes toevoegen]
search = |rest splunk_server=local /services/data/macros \
| search eai:acl.app = "ekesh"\
| table title definition\
| search  definition = "*DEFINIEER*" OR definition= "KLANTNAAM"\
\
``` Toevoegen Klantnaam ```\
| eval klantnaam = `klantnaam`

[Mem OR Cpu Usage > 85% (p90)]
search = index="_introspection" sourcetype=splunk_resource_usage component=Hostwide \
|  stats  p90(data.mem) as mem p90(data.mem_used) as memused p90(data.cpu_system_pct) as systemcpu p90(data.cpu_user_pct) as usercpu  by host _time\
|  eval mempct = round(memused/mem*100,2) \
|  eval cpupct = systemcpu + usercpu \
|  stats max(cpupct) as cpu max(mempct) as mem by  host\
| where cpu > 90 OR mempct > 90\
\
``` Toevoegen Klantnaam ```\
| eval klantnaam = `klantnaam`

[Replicatie_Failure]
search = index=_internal sourcetype=splunkd "because replication was unsuccessful. replicationStatus Failed failure info: failed_because"\
| stats count, max(_time) AS mostRecent by host, message \
| eval mostRecent=strftime(mostRecent,"%+")\
\
``` Toevoegen Klantnaam ```\
| eval klantnaam = `klantnaam`

[Splunk HF's/SUF's are down]
search = | makeresults\
| eval hosts = `HF_SUF_hosts`\
| makemv delim="," hosts\
| mvexpand hosts\
| rename hosts as host\
| join max=0 host type=left [| search index=_internal sourcetype=splunkd | stats c as counts by host ]\
| table host counts\
| search NOT host="NVT"\
| where isnull(counts)\
| search NOT host="DEFINIEER_HF_en_Intermediate_HOSTS" OR host="NVT"\
\
``` Toevoegen Klantnaam ```\
| eval klantnaam = `klantnaam`

[Splunk core servers are down]
search = | inputlookup assets.csv\
| dedup host\
| table host\
| join type=left host [search index=_internal sourcetype=splunkd | stats c as counts by host| table host counts]\
| where isnull(counts)\
\
``` Toevoegen Klantnaam ```\
| eval klantnaam = `klantnaam`

[alerting skipped searches]
search = index=_internal status=skipped source="/opt/splunk/var/log/splunk/scheduler.log" NOT "*concurrent*"\
\
``` Toevoegen Klantnaam ```\
| eval klantnaam = `klantnaam`

[Abnormal State of Indexer Processor]
action.email = 1
action.email.inline = 1
action.email.sendresults = 1
action.email.to = support@smtware.com
action.email.useNSSubject = 1
action.webhook.enable_allowlist = 0
alert.suppress = 1
alert.suppress.period = 30m
alert.track = 0
counttype = number of events
cron_schedule = 3,8,13,18,23,28,33,38,43,48,53,58 * * * *
dispatch.earliest_time = -24h@h
dispatch.latest_time = now
display.events.fields = ["host","source","sourcetype","tag","tag::eventtype","message"]
display.general.type = statistics
display.page.search.mode = verbose
display.page.search.tab = statistics
enableSched = 1
quantity = 0
relation = greater than
request.ui_dispatch_app = controlpane
request.ui_dispatch_view = search
search = | rest splunk_server_group=dmc_group_indexer /services/server/introspection/indexer \
| fields splunk_server, average_KBps, status, reason \
| where status != "normal" \
| eval average_KBps = round(average_KBps, 0) \
| eval status= if(status=="normal", status, status." - ".reason) \
| fields - reason \
| rename splunk_server as Instance, average_KBps as "Average KB/s (last 30s)", status as Status\
\
``` Toevoegen Klantnaam ```\
| eval klantnaam = `klantnaam`

[Critical System Physical Memory Usage]
action.email = 1
action.email.inline = 1
action.email.sendresults = 1
action.email.to = support@smtware.com
action.email.useNSSubject = 1
action.webhook.enable_allowlist = 0
alert.suppress = 1
alert.suppress.period = 30m
alert.track = 0
counttype = number of events
cron_schedule = 3,8,13,18,23,28,33,38,43,48,53,58 * * * *
dispatch.earliest_time = -24h@h
dispatch.latest_time = now
display.events.fields = ["host","source","sourcetype","tag","tag::eventtype","message"]
display.general.type = statistics
display.page.search.mode = verbose
display.page.search.tab = statistics
enableSched = 1
quantity = 0
relation = greater than
request.ui_dispatch_app = controlpane
request.ui_dispatch_view = search
search = | rest splunk_server_group=dmc_group_* /services/server/status/resource-usage/hostwide \
| eval percentage=round(mem_used/mem,3)*100 \
| where percentage > 90 \
| fields splunk_server, percentage, mem_used, mem \
| rename splunk_server AS Instance, mem AS "Physical memory installed (MB)", percentage AS "Memory used (%)", mem_used AS "Memory used (MB)"\
\
``` Toevoegen Klantnaam ```\
| eval klantnaam = `klantnaam`

[Expired and Soon To Expire Licenses]
action.email = 1
action.email.inline = 1
action.email.sendresults = 1
action.email.to = support@smtware.com
action.email.useNSSubject = 1
action.webhook.enable_allowlist = 0
alert.suppress = 0
alert.track = 0
counttype = number of events
cron_schedule = 3 0 * * *
dispatch.earliest_time = -24h@h
dispatch.latest_time = now
display.events.fields = ["host","source","sourcetype","tag","tag::eventtype","message"]
display.general.type = statistics
display.page.search.mode = verbose
display.page.search.tab = statistics
enableSched = 1
quantity = 0
relation = greater than
request.ui_dispatch_app = controlpane
request.ui_dispatch_view = search
search = | rest splunk_server_group=dmc_group_license_master /services/licenser/licenses \
| join type=outer group_id splunk_server [ \
    rest splunk_server_group=dmc_group_license_master /services/licenser/groups \
    | where is_active = 1 \
    | rename title AS group_id \
    | fields is_active group_id splunk_server] \
| where is_active = 1 \
| eval days_left = floor((expiration_time - now()) / 86400) \
| where NOT (quota = 1048576 OR label == "Splunk Enterprise Reset Warnings" OR label == "Splunk Lite Reset Warnings") \
| eventstats max(eval(if(days_left >= 14, 1, 0))) as has_valid_license by splunk_server \
| where has_valid_license == 0 AND (status == "EXPIRED" OR days_left < 15) \
| eval expiration_status = case(days_left >= 14, days_left." days left", days_left < 14 AND days_left >= 0, "Expires soon: ".days_left." days left", days_left < 0, "Expired") \
| eval total_gb=round(quota/1024/1024/1024,3) \
| fields splunk_server label license_hash type group_id total_gb expiration_time expiration_status \
| convert ctime(expiration_time) \
| rename splunk_server AS Instance label AS "Label" license_hash AS "License Hash" type AS Type group_id AS Group total_gb AS Size expiration_time AS "Expires On" expiration_status AS Status\
\
``` Toevoegen Klantnaam ```\
| eval klantnaam = `klantnaam`

[Total License Usage Near Daily Quota]
action.email = 1
action.email.inline = 1
action.email.sendresults = 1
action.email.to = support@smtware.com
action.email.useNSSubject = 1
action.webhook.enable_allowlist = 0
alert.suppress = 1
alert.suppress.period = 4h
alert.track = 0
counttype = number of events
cron_schedule = 3,33 * * * *
dispatch.earliest_time = -24h@h
dispatch.latest_time = now
display.events.fields = ["host","source","sourcetype","tag","tag::eventtype","message"]
display.general.type = statistics
display.page.search.mode = verbose
display.page.search.tab = statistics
enableSched = 1
quantity = 0
relation = greater than
request.ui_dispatch_app = controlpane
request.ui_dispatch_view = search
search = | rest splunk_server_group=dmc_group_license_master /services/licenser/groups | search is_active=1 | eval stack_id=stack_ids | mvexpand stack_id \
| join type=outer stack_id splunk_server [rest splunk_server_group=dmc_group_license_master /services/licenser/pools] \
| fields splunk_server,stack_id,effective_quota,used_bytes \
| stats sum(used_bytes) as used_bytes max(effective_quota) as stack_quota by stack_id \
| eval usedGB=round(used_bytes/1024/1024/1024,3) \
| eval totalGB=round(stack_quota/1024/1024/1024,3) \
| eval percentage=round(usedGB / totalGB, 3)*100 \
| fields stack_id, percentage, usedGB, totalGB \
| where percentage > 90 \
| rename stack_id AS Instance, percentage AS "License quota used (%)", usedGB AS "License quota used (GB)", totalGB as "Total license quota (GB)"\
\
``` Toevoegen Klantnaam ```\
| eval klantnaam = `klantnaam`
